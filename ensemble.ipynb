{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf-acno-projects/image-classification\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os \n",
    "import re\n",
    "import numpy as np\n",
    "os.chdir('/tf-acno-projects/image-classification/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = 'models/first_model_old' + '.keras'\n",
    "path2 = 'models/31_oct_24_final_model' + '.keras'\n",
    "path3 = 'models/1_nov_24_final_model2' + '.keras'\n",
    "path4 = 'models/1_nov_24_final_model3' + '.keras'\n",
    "reg_pattern = r\".*\\.jpg$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    0: 'angry',\n",
    "    1: 'disgusted',\n",
    "    2: 'happy',\n",
    "    3: 'sad',\n",
    "    4: 'shocked'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "try:\n",
    "    model1 = load_model(path1)\n",
    "    model2 = load_model(path2)\n",
    "    model3 = load_model(path3)\n",
    "    model4 = load_model(path4)\n",
    "    print(\"Models loaded successfully\")\n",
    "except:\n",
    "    print(\"Models Loading Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test/angry_guy.jpg', 'test/sad_guy.jpg', 'test/shocked_guy.jpg']\n"
     ]
    }
   ],
   "source": [
    "testing_pictures = [os.path.join('test/',path) for path in os.listdir('test/') if re.match(reg_pattern,path,re.IGNORECASE)]\n",
    "print(testing_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "For test/angry_guy.jpg , Prediction: happy, With Percentage of : 85.32\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "For test/sad_guy.jpg , Prediction: sad, With Percentage of : 50.00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "For test/shocked_guy.jpg , Prediction: angry, With Percentage of : 50.00\n"
     ]
    }
   ],
   "source": [
    "for img in testing_pictures:\n",
    "    try:\n",
    "        loaded_image = image.load_img(img,target_size=(128,128))\n",
    "    except:\n",
    "        print(\"Error Loading the image\")\n",
    "        \n",
    "    image_arr = image.img_to_array(loaded_image)\n",
    "    image_arr = tf.expand_dims(image_arr,axis=0)\n",
    "    \n",
    "    ensemble = model1.predict(image_arr)+model2.predict(image_arr)+model3.predict(image_arr)+model4.predict(image_arr)\n",
    "    ensemble_res = ensemble/4\n",
    "\n",
    "    predicted_class = tf.argmax(ensemble_res,axis=1).numpy()[0] #axis=1 means it looks across the class probabilities for each prediction\n",
    "    probability = ensemble_res[0][predicted_class] * 100\n",
    "    \n",
    "    print(f\"For {img} , Prediction: {class_mapping.get(predicted_class, 'UNKNOWN')}, With Percentage of : {probability:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "For test/angry_guy.jpg , Prediction: happy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "For test/sad_guy.jpg , Prediction: sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "For test/shocked_guy.jpg , Prediction: angry\n"
     ]
    }
   ],
   "source": [
    "for img in testing_pictures:\n",
    "    try:\n",
    "        loaded_image = image.load_img(img,target_size=(128,128))\n",
    "    except:\n",
    "        print(\"Error Loading the image\")\n",
    "    image_arr = image.img_to_array(loaded_image)\n",
    "    image_arr = tf.expand_dims(image_arr,axis=0)\n",
    "    # Make predictions for each model\n",
    "    pred1 = model1.predict(image_arr)\n",
    "    pred2 = model2.predict(image_arr)\n",
    "    pred3 = model3.predict(image_arr)\n",
    "    pred4 = model3.predict(image_arr)\n",
    "\n",
    "    # Get the predicted classes\n",
    "    class1 = tf.argmax(pred1, axis=1).numpy()[0] ## for example pred = [ 0.1 0.5 0.6 ] => argmax returns 2 then its [2] cause numpy\n",
    "    class2 = tf.argmax(pred2, axis=1).numpy()[0]\n",
    "    class3 = tf.argmax(pred3, axis=1).numpy()[0]\n",
    "    class4 = tf.argmax(pred4, axis=1).numpy()[0]\n",
    "    weights = [2,1,1,1]\n",
    "    # Combine predictions into a list\n",
    "    predictions = [class1]*weights[0]+[class2]*weights[1]+[class3]*weights[2]+[class4]*weights[3]\n",
    "\n",
    "    # Get the most common prediction (voting)\n",
    "    ensemble_prediction = np.bincount(predictions).argmax() ## here bincount for like [ 0 1 1 ] means that\n",
    "    # for class 0 it appeared one time , class 1 appeared 2 times and last class appreared 0 times so\n",
    "    # bincount => [1 2 0 ] and argmax becomes index of highest pred => 1 so CLASS 1 is the voted\n",
    "    print(f\"For {img} , Prediction: {class_mapping.get(ensemble_prediction, 'UNKNOWN')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
