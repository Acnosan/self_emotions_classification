{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/tf-acno-projects/image-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:56:57.140438: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-12 18:56:57.140548: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-12 18:56:57.140823: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-12 18:56:57.170358: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory limit set for GPU\n",
      "\n",
      "XLA Status Check:\n",
      "XLA JIT enabled: autoclustering\n",
      "XLA devices: [LogicalDevice(name='/device:XLA_GPU:0', device_type='XLA_GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:56:59.993121: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 18:57:00.020430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 18:57:00.020457: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 18:57:00.033113: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xb4c5670 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-12 18:57:00.033142: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-12-12 18:57:00.033506: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2024-12-12 18:57:00.033630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 18:57:00.033656: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 18:57:00.033668: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 18:57:00.163727: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 18:57:00.163749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-12-12 18:57:00.163771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 18:57:00.163790: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 18:57:00.163808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6000 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-12-12 18:57:00.167738: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xb12a4c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-12 18:57:00.167757: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050, Compute Capability 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.data.experimental import cardinality\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Precision,Recall,CategoricalAccuracy\n",
    "\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "tf.config.optimizer.set_jit(True)  # Enable XLA\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_virtual_device_configuration(\n",
    "                gpu,\n",
    "                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=6000)]  # Limit GPU memory usage\n",
    "            )\n",
    "            print(f\"Memory limit set for GPU\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        \n",
    "# Before training\n",
    "print(\"\\nXLA Status Check:\")\n",
    "print(f\"XLA JIT enabled: {tf.config.optimizer.get_jit()}\")\n",
    "print(f\"XLA devices: {tf.config.list_logical_devices('XLA_GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3050, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:57:00.415234: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = tf.keras.models.load_model('models/1_2024_12_5_0.912.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'faces_data'\n",
    "autotune = tf.data.AUTOTUNE\n",
    "img_size = (128,128,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(is_training,dataset,batch_size,shuffle_buffer=None):\n",
    "    dataset = dataset.map(\n",
    "        lambda x,y: (tf.cast(x,tf.float32)/255.0,y),\n",
    "        num_parallel_calls = autotune\n",
    "    )\n",
    "    \n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(shuffle_buffer)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset.prefetch(autotune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11107 files belonging to 5 classes.\n",
      "class 0 : label : angry\n",
      "\n",
      "class 1 : label : disgusted\n",
      "\n",
      "class 2 : label : happy\n",
      "\n",
      "class 3 : label : sad\n",
      "\n",
      "class 4 : label : shocked\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    image_size=(128,128),\n",
    "    label_mode='categorical',# Ensure labels are one-hot encoded\n",
    "    batch_size= None,\n",
    ")\n",
    "\n",
    "for i,class_name in enumerate(dataset.class_names):\n",
    "    print(f\"class {i} : label : {class_name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = cardinality(dataset).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8*DATASET_SIZE)\n",
    "test_size = int(0.1*DATASET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_split = dataset.take(train_size)\n",
    "remaining = dataset.skip(train_size)\n",
    "test_split = remaining.take(test_size)\n",
    "validation_split = remaining.skip(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    #EarlyStopping(monitor='val_loss',patience=20,min_delta=0.00001),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\",factor=0.8, patience=5,min_delta=0.001,min_lr=1e-6),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = prepare_dataset(True,dataset,batch_size,4000)\n",
    "test_dataset = prepare_dataset(False,dataset,batch_size)\n",
    "validation_dataset = prepare_dataset(False,dataset,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate),\n",
    "    loss = CategoricalCrossentropy(),\n",
    "    metrics = [Precision(),Recall(),CategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:57:04.465159: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-12 18:57:04.493867: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-12-12 18:57:06.207026: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-12-12 18:57:11.739885: I tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:328] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_226', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2024-12-12 18:57:11.940244: I tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:328] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_226', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 21s 29ms/step - loss: 1.7318 - precision: 0.6916 - recall: 0.3071 - categorical_accuracy: 0.4717 - val_loss: 1.1306 - val_precision: 0.8749 - val_recall: 0.3735 - val_categorical_accuracy: 0.5871 - lr: 5.0000e-04\n",
      "Epoch 2/150\n",
      "345/348 [============================>.] - ETA: 0s - loss: 1.2262 - precision: 0.8035 - recall: 0.3434 - categorical_accuracy: 0.5375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:57:32.771409: I tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:328] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_166', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - ETA: 0s - loss: 1.2248 - precision: 0.8043 - recall: 0.3440 - categorical_accuracy: 0.5380"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:57:38.796046: I tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:328] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_177', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-12-12 18:57:39.334178: I tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:328] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_177', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 16s 45ms/step - loss: 1.2248 - precision: 0.8043 - recall: 0.3440 - categorical_accuracy: 0.5380 - val_loss: 0.9738 - val_precision: 0.8885 - val_recall: 0.4499 - val_categorical_accuracy: 0.6342 - lr: 5.0000e-04\n",
      "Epoch 3/150\n",
      "348/348 [==============================] - 6s 15ms/step - loss: 1.0897 - precision: 0.8292 - recall: 0.4021 - categorical_accuracy: 0.5701 - val_loss: 0.8721 - val_precision: 0.9152 - val_recall: 0.5007 - val_categorical_accuracy: 0.6762 - lr: 5.0000e-04\n",
      "Epoch 4/150\n",
      "348/348 [==============================] - 6s 15ms/step - loss: 1.0199 - precision: 0.8397 - recall: 0.4411 - categorical_accuracy: 0.5913 - val_loss: 0.8021 - val_precision: 0.9277 - val_recall: 0.5364 - val_categorical_accuracy: 0.7002 - lr: 5.0000e-04\n",
      "Epoch 5/150\n",
      "348/348 [==============================] - 5s 14ms/step - loss: 0.9499 - precision: 0.8455 - recall: 0.4774 - categorical_accuracy: 0.6179 - val_loss: 0.7314 - val_precision: 0.9266 - val_recall: 0.5856 - val_categorical_accuracy: 0.7292 - lr: 5.0000e-04\n",
      "Epoch 6/150\n",
      "348/348 [==============================] - 6s 15ms/step - loss: 0.9006 - precision: 0.8474 - recall: 0.5025 - categorical_accuracy: 0.6346 - val_loss: 0.6764 - val_precision: 0.9296 - val_recall: 0.6138 - val_categorical_accuracy: 0.7465 - lr: 5.0000e-04\n",
      "Epoch 7/150\n",
      "348/348 [==============================] - 6s 15ms/step - loss: 0.8641 - precision: 0.8568 - recall: 0.5253 - categorical_accuracy: 0.6547 - val_loss: 0.6383 - val_precision: 0.9230 - val_recall: 0.6450 - val_categorical_accuracy: 0.7610 - lr: 5.0000e-04\n",
      "Epoch 8/150\n",
      "348/348 [==============================] - 5s 14ms/step - loss: 0.8313 - precision: 0.8537 - recall: 0.5484 - categorical_accuracy: 0.6709 - val_loss: 0.6084 - val_precision: 0.9396 - val_recall: 0.6587 - val_categorical_accuracy: 0.7750 - lr: 5.0000e-04\n",
      "Epoch 9/150\n",
      "348/348 [==============================] - 5s 14ms/step - loss: 0.7913 - precision: 0.8651 - recall: 0.5663 - categorical_accuracy: 0.6791 - val_loss: 0.5760 - val_precision: 0.9356 - val_recall: 0.6836 - val_categorical_accuracy: 0.7867 - lr: 5.0000e-04\n",
      "Epoch 10/150\n",
      "348/348 [==============================] - 7s 18ms/step - loss: 0.7773 - precision: 0.8660 - recall: 0.5788 - categorical_accuracy: 0.6897 - val_loss: 0.5699 - val_precision: 0.9420 - val_recall: 0.6891 - val_categorical_accuracy: 0.7925 - lr: 5.0000e-04\n",
      "Epoch 11/150\n",
      "348/348 [==============================] - 7s 16ms/step - loss: 0.7626 - precision: 0.8645 - recall: 0.5883 - categorical_accuracy: 0.6908 - val_loss: 0.5488 - val_precision: 0.9440 - val_recall: 0.7017 - val_categorical_accuracy: 0.7975 - lr: 5.0000e-04\n",
      "Epoch 12/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.7438 - precision: 0.8665 - recall: 0.5976 - categorical_accuracy: 0.6971 - val_loss: 0.5259 - val_precision: 0.9415 - val_recall: 0.7138 - val_categorical_accuracy: 0.8046 - lr: 5.0000e-04\n",
      "Epoch 13/150\n",
      "348/348 [==============================] - 5s 13ms/step - loss: 0.7295 - precision: 0.8703 - recall: 0.6083 - categorical_accuracy: 0.7052 - val_loss: 0.5168 - val_precision: 0.9442 - val_recall: 0.7243 - val_categorical_accuracy: 0.8134 - lr: 5.0000e-04\n",
      "Epoch 14/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.7151 - precision: 0.8734 - recall: 0.6191 - categorical_accuracy: 0.7136 - val_loss: 0.5006 - val_precision: 0.9532 - val_recall: 0.7349 - val_categorical_accuracy: 0.8192 - lr: 5.0000e-04\n",
      "Epoch 15/150\n",
      "348/348 [==============================] - 5s 13ms/step - loss: 0.6946 - precision: 0.8781 - recall: 0.6326 - categorical_accuracy: 0.7204 - val_loss: 0.4940 - val_precision: 0.9494 - val_recall: 0.7386 - val_categorical_accuracy: 0.8179 - lr: 5.0000e-04\n",
      "Epoch 16/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.6828 - precision: 0.8799 - recall: 0.6358 - categorical_accuracy: 0.7240 - val_loss: 0.4820 - val_precision: 0.9502 - val_recall: 0.7478 - val_categorical_accuracy: 0.8225 - lr: 5.0000e-04\n",
      "Epoch 17/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.6831 - precision: 0.8800 - recall: 0.6372 - categorical_accuracy: 0.7249 - val_loss: 0.4603 - val_precision: 0.9516 - val_recall: 0.7615 - val_categorical_accuracy: 0.8304 - lr: 5.0000e-04\n",
      "Epoch 18/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.6683 - precision: 0.8830 - recall: 0.6459 - categorical_accuracy: 0.7315 - val_loss: 0.4631 - val_precision: 0.9565 - val_recall: 0.7591 - val_categorical_accuracy: 0.8317 - lr: 5.0000e-04\n",
      "Epoch 19/150\n",
      "348/348 [==============================] - 5s 11ms/step - loss: 0.6613 - precision: 0.8829 - recall: 0.6509 - categorical_accuracy: 0.7350 - val_loss: 0.4530 - val_precision: 0.9498 - val_recall: 0.7651 - val_categorical_accuracy: 0.8318 - lr: 5.0000e-04\n",
      "Epoch 20/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.6550 - precision: 0.8888 - recall: 0.6568 - categorical_accuracy: 0.7355 - val_loss: 0.4574 - val_precision: 0.9482 - val_recall: 0.7621 - val_categorical_accuracy: 0.8292 - lr: 5.0000e-04\n",
      "Epoch 21/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.6430 - precision: 0.8884 - recall: 0.6623 - categorical_accuracy: 0.7457 - val_loss: 0.4531 - val_precision: 0.9551 - val_recall: 0.7644 - val_categorical_accuracy: 0.8370 - lr: 5.0000e-04\n",
      "Epoch 22/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.6402 - precision: 0.8901 - recall: 0.6655 - categorical_accuracy: 0.7494 - val_loss: 0.4411 - val_precision: 0.9487 - val_recall: 0.7738 - val_categorical_accuracy: 0.8386 - lr: 5.0000e-04\n",
      "Epoch 23/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.6325 - precision: 0.8877 - recall: 0.6699 - categorical_accuracy: 0.7455 - val_loss: 0.4357 - val_precision: 0.9532 - val_recall: 0.7762 - val_categorical_accuracy: 0.8405 - lr: 5.0000e-04\n",
      "Epoch 24/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.6304 - precision: 0.8926 - recall: 0.6722 - categorical_accuracy: 0.7502 - val_loss: 0.4289 - val_precision: 0.9578 - val_recall: 0.7800 - val_categorical_accuracy: 0.8458 - lr: 5.0000e-04\n",
      "Epoch 25/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.6207 - precision: 0.8951 - recall: 0.6738 - categorical_accuracy: 0.7529 - val_loss: 0.4488 - val_precision: 0.9559 - val_recall: 0.7685 - val_categorical_accuracy: 0.8385 - lr: 5.0000e-04\n",
      "Epoch 26/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.6215 - precision: 0.8953 - recall: 0.6772 - categorical_accuracy: 0.7543 - val_loss: 0.4349 - val_precision: 0.9588 - val_recall: 0.7762 - val_categorical_accuracy: 0.8444 - lr: 5.0000e-04\n",
      "Epoch 27/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.6129 - precision: 0.8951 - recall: 0.6797 - categorical_accuracy: 0.7593 - val_loss: 0.4177 - val_precision: 0.9565 - val_recall: 0.7871 - val_categorical_accuracy: 0.8479 - lr: 5.0000e-04\n",
      "Epoch 28/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.6119 - precision: 0.8965 - recall: 0.6833 - categorical_accuracy: 0.7596 - val_loss: 0.4251 - val_precision: 0.9524 - val_recall: 0.7855 - val_categorical_accuracy: 0.8451 - lr: 5.0000e-04\n",
      "Epoch 29/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.6134 - precision: 0.8941 - recall: 0.6803 - categorical_accuracy: 0.7565 - val_loss: 0.4183 - val_precision: 0.9578 - val_recall: 0.7888 - val_categorical_accuracy: 0.8502 - lr: 5.0000e-04\n",
      "Epoch 30/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.5976 - precision: 0.8993 - recall: 0.6906 - categorical_accuracy: 0.7629 - val_loss: 0.4079 - val_precision: 0.9503 - val_recall: 0.7947 - val_categorical_accuracy: 0.8473 - lr: 5.0000e-04\n",
      "Epoch 31/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.6011 - precision: 0.8969 - recall: 0.6889 - categorical_accuracy: 0.7600 - val_loss: 0.4127 - val_precision: 0.9524 - val_recall: 0.7938 - val_categorical_accuracy: 0.8476 - lr: 5.0000e-04\n",
      "Epoch 32/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.6019 - precision: 0.8978 - recall: 0.6896 - categorical_accuracy: 0.7606 - val_loss: 0.4056 - val_precision: 0.9582 - val_recall: 0.7922 - val_categorical_accuracy: 0.8516 - lr: 5.0000e-04\n",
      "Epoch 33/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.5929 - precision: 0.9004 - recall: 0.6948 - categorical_accuracy: 0.7659 - val_loss: 0.4069 - val_precision: 0.9576 - val_recall: 0.7927 - val_categorical_accuracy: 0.8515 - lr: 5.0000e-04\n",
      "Epoch 34/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.5933 - precision: 0.9000 - recall: 0.6958 - categorical_accuracy: 0.7671 - val_loss: 0.4070 - val_precision: 0.9639 - val_recall: 0.7846 - val_categorical_accuracy: 0.8538 - lr: 5.0000e-04\n",
      "Epoch 35/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.5836 - precision: 0.9034 - recall: 0.6989 - categorical_accuracy: 0.7693 - val_loss: 0.4008 - val_precision: 0.9589 - val_recall: 0.7994 - val_categorical_accuracy: 0.8558 - lr: 5.0000e-04\n",
      "Epoch 36/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.5822 - precision: 0.9000 - recall: 0.7005 - categorical_accuracy: 0.7736 - val_loss: 0.4040 - val_precision: 0.9631 - val_recall: 0.7962 - val_categorical_accuracy: 0.8555 - lr: 5.0000e-04\n",
      "Epoch 37/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.5637 - precision: 0.9060 - recall: 0.7100 - categorical_accuracy: 0.7792 - val_loss: 0.3897 - val_precision: 0.9619 - val_recall: 0.8031 - val_categorical_accuracy: 0.8585 - lr: 5.0000e-04\n",
      "Epoch 38/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.5683 - precision: 0.9050 - recall: 0.7117 - categorical_accuracy: 0.7780 - val_loss: 0.3942 - val_precision: 0.9620 - val_recall: 0.8006 - val_categorical_accuracy: 0.8565 - lr: 5.0000e-04\n",
      "Epoch 39/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.5786 - precision: 0.9023 - recall: 0.7032 - categorical_accuracy: 0.7726 - val_loss: 0.3972 - val_precision: 0.9583 - val_recall: 0.8014 - val_categorical_accuracy: 0.8560 - lr: 5.0000e-04\n",
      "Epoch 40/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.5760 - precision: 0.9065 - recall: 0.7055 - categorical_accuracy: 0.7743 - val_loss: 0.3896 - val_precision: 0.9611 - val_recall: 0.8032 - val_categorical_accuracy: 0.8586 - lr: 5.0000e-04\n",
      "Epoch 41/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.5726 - precision: 0.9075 - recall: 0.7075 - categorical_accuracy: 0.7776 - val_loss: 0.3944 - val_precision: 0.9605 - val_recall: 0.7998 - val_categorical_accuracy: 0.8577 - lr: 5.0000e-04\n",
      "Epoch 42/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.5583 - precision: 0.9060 - recall: 0.7091 - categorical_accuracy: 0.7802 - val_loss: 0.3888 - val_precision: 0.9607 - val_recall: 0.8046 - val_categorical_accuracy: 0.8600 - lr: 5.0000e-04\n",
      "Epoch 43/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.5568 - precision: 0.9074 - recall: 0.7105 - categorical_accuracy: 0.7804 - val_loss: 0.3841 - val_precision: 0.9629 - val_recall: 0.8053 - val_categorical_accuracy: 0.8595 - lr: 4.0000e-04\n",
      "Epoch 44/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.5502 - precision: 0.9140 - recall: 0.7142 - categorical_accuracy: 0.7867 - val_loss: 0.3782 - val_precision: 0.9616 - val_recall: 0.8082 - val_categorical_accuracy: 0.8610 - lr: 4.0000e-04\n",
      "Epoch 45/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.5494 - precision: 0.9087 - recall: 0.7174 - categorical_accuracy: 0.7860 - val_loss: 0.3827 - val_precision: 0.9605 - val_recall: 0.8090 - val_categorical_accuracy: 0.8618 - lr: 4.0000e-04\n",
      "Epoch 46/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.5416 - precision: 0.9140 - recall: 0.7185 - categorical_accuracy: 0.7870 - val_loss: 0.3774 - val_precision: 0.9628 - val_recall: 0.8098 - val_categorical_accuracy: 0.8633 - lr: 4.0000e-04\n",
      "Epoch 47/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.5354 - precision: 0.9157 - recall: 0.7251 - categorical_accuracy: 0.7874 - val_loss: 0.3741 - val_precision: 0.9618 - val_recall: 0.8117 - val_categorical_accuracy: 0.8626 - lr: 4.0000e-04\n",
      "Epoch 48/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.5265 - precision: 0.9179 - recall: 0.7267 - categorical_accuracy: 0.7951 - val_loss: 0.3713 - val_precision: 0.9603 - val_recall: 0.8109 - val_categorical_accuracy: 0.8621 - lr: 4.0000e-04\n",
      "Epoch 49/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.5265 - precision: 0.9157 - recall: 0.7272 - categorical_accuracy: 0.7938 - val_loss: 0.3739 - val_precision: 0.9601 - val_recall: 0.8128 - val_categorical_accuracy: 0.8624 - lr: 4.0000e-04\n",
      "Epoch 50/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.5234 - precision: 0.9163 - recall: 0.7337 - categorical_accuracy: 0.7965 - val_loss: 0.3712 - val_precision: 0.9640 - val_recall: 0.8108 - val_categorical_accuracy: 0.8628 - lr: 4.0000e-04\n",
      "Epoch 51/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.5265 - precision: 0.9175 - recall: 0.7305 - categorical_accuracy: 0.7925 - val_loss: 0.3662 - val_precision: 0.9627 - val_recall: 0.8131 - val_categorical_accuracy: 0.8642 - lr: 4.0000e-04\n",
      "Epoch 52/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.5273 - precision: 0.9142 - recall: 0.7297 - categorical_accuracy: 0.7951 - val_loss: 0.3656 - val_precision: 0.9629 - val_recall: 0.8140 - val_categorical_accuracy: 0.8643 - lr: 4.0000e-04\n",
      "Epoch 53/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.5216 - precision: 0.9190 - recall: 0.7307 - categorical_accuracy: 0.7954 - val_loss: 0.3711 - val_precision: 0.9656 - val_recall: 0.8102 - val_categorical_accuracy: 0.8649 - lr: 4.0000e-04\n",
      "Epoch 54/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.5268 - precision: 0.9152 - recall: 0.7267 - categorical_accuracy: 0.7897 - val_loss: 0.3634 - val_precision: 0.9640 - val_recall: 0.8127 - val_categorical_accuracy: 0.8633 - lr: 4.0000e-04\n",
      "Epoch 55/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.5138 - precision: 0.9234 - recall: 0.7333 - categorical_accuracy: 0.7970 - val_loss: 0.3622 - val_precision: 0.9616 - val_recall: 0.8144 - val_categorical_accuracy: 0.8651 - lr: 4.0000e-04\n",
      "Epoch 56/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.5090 - precision: 0.9175 - recall: 0.7357 - categorical_accuracy: 0.8010 - val_loss: 0.3729 - val_precision: 0.9542 - val_recall: 0.8172 - val_categorical_accuracy: 0.8633 - lr: 4.0000e-04\n",
      "Epoch 57/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.5199 - precision: 0.9161 - recall: 0.7351 - categorical_accuracy: 0.7972 - val_loss: 0.3629 - val_precision: 0.9632 - val_recall: 0.8161 - val_categorical_accuracy: 0.8662 - lr: 4.0000e-04\n",
      "Epoch 58/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.5208 - precision: 0.9190 - recall: 0.7358 - categorical_accuracy: 0.7965 - val_loss: 0.3624 - val_precision: 0.9629 - val_recall: 0.8146 - val_categorical_accuracy: 0.8650 - lr: 4.0000e-04\n",
      "Epoch 59/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.5145 - precision: 0.9173 - recall: 0.7343 - categorical_accuracy: 0.7965 - val_loss: 0.3617 - val_precision: 0.9607 - val_recall: 0.8167 - val_categorical_accuracy: 0.8663 - lr: 4.0000e-04\n",
      "Epoch 60/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.5019 - precision: 0.9217 - recall: 0.7423 - categorical_accuracy: 0.8047 - val_loss: 0.3620 - val_precision: 0.9631 - val_recall: 0.8161 - val_categorical_accuracy: 0.8663 - lr: 4.0000e-04\n",
      "Epoch 61/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.5048 - precision: 0.9218 - recall: 0.7379 - categorical_accuracy: 0.8000 - val_loss: 0.3574 - val_precision: 0.9664 - val_recall: 0.8169 - val_categorical_accuracy: 0.8677 - lr: 3.2000e-04\n",
      "Epoch 62/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4930 - precision: 0.9240 - recall: 0.7424 - categorical_accuracy: 0.8039 - val_loss: 0.3566 - val_precision: 0.9648 - val_recall: 0.8166 - val_categorical_accuracy: 0.8669 - lr: 3.2000e-04\n",
      "Epoch 63/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.4977 - precision: 0.9230 - recall: 0.7422 - categorical_accuracy: 0.8030 - val_loss: 0.3583 - val_precision: 0.9639 - val_recall: 0.8168 - val_categorical_accuracy: 0.8673 - lr: 3.2000e-04\n",
      "Epoch 64/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.4972 - precision: 0.9248 - recall: 0.7447 - categorical_accuracy: 0.8027 - val_loss: 0.3544 - val_precision: 0.9629 - val_recall: 0.8185 - val_categorical_accuracy: 0.8670 - lr: 3.2000e-04\n",
      "Epoch 65/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4967 - precision: 0.9223 - recall: 0.7383 - categorical_accuracy: 0.7988 - val_loss: 0.3545 - val_precision: 0.9656 - val_recall: 0.8182 - val_categorical_accuracy: 0.8673 - lr: 3.2000e-04\n",
      "Epoch 66/150\n",
      "348/348 [==============================] - 5s 11ms/step - loss: 0.4823 - precision: 0.9269 - recall: 0.7498 - categorical_accuracy: 0.8095 - val_loss: 0.3511 - val_precision: 0.9654 - val_recall: 0.8196 - val_categorical_accuracy: 0.8682 - lr: 3.2000e-04\n",
      "Epoch 67/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4872 - precision: 0.9263 - recall: 0.7477 - categorical_accuracy: 0.8077 - val_loss: 0.3514 - val_precision: 0.9656 - val_recall: 0.8191 - val_categorical_accuracy: 0.8686 - lr: 3.2000e-04\n",
      "Epoch 68/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4863 - precision: 0.9254 - recall: 0.7466 - categorical_accuracy: 0.8072 - val_loss: 0.3488 - val_precision: 0.9655 - val_recall: 0.8193 - val_categorical_accuracy: 0.8686 - lr: 3.2000e-04\n",
      "Epoch 69/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4906 - precision: 0.9232 - recall: 0.7442 - categorical_accuracy: 0.8015 - val_loss: 0.3526 - val_precision: 0.9688 - val_recall: 0.8167 - val_categorical_accuracy: 0.8691 - lr: 3.2000e-04\n",
      "Epoch 70/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.4871 - precision: 0.9290 - recall: 0.7488 - categorical_accuracy: 0.8059 - val_loss: 0.3468 - val_precision: 0.9655 - val_recall: 0.8191 - val_categorical_accuracy: 0.8689 - lr: 3.2000e-04\n",
      "Epoch 71/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.4854 - precision: 0.9284 - recall: 0.7491 - categorical_accuracy: 0.8064 - val_loss: 0.3487 - val_precision: 0.9660 - val_recall: 0.8190 - val_categorical_accuracy: 0.8685 - lr: 3.2000e-04\n",
      "Epoch 72/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.4885 - precision: 0.9264 - recall: 0.7428 - categorical_accuracy: 0.8061 - val_loss: 0.3501 - val_precision: 0.9654 - val_recall: 0.8193 - val_categorical_accuracy: 0.8687 - lr: 3.2000e-04\n",
      "Epoch 73/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.4824 - precision: 0.9282 - recall: 0.7487 - categorical_accuracy: 0.8102 - val_loss: 0.3469 - val_precision: 0.9665 - val_recall: 0.8192 - val_categorical_accuracy: 0.8683 - lr: 3.2000e-04\n",
      "Epoch 74/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4720 - precision: 0.9309 - recall: 0.7531 - categorical_accuracy: 0.8112 - val_loss: 0.3460 - val_precision: 0.9646 - val_recall: 0.8206 - val_categorical_accuracy: 0.8684 - lr: 3.2000e-04\n",
      "Epoch 75/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4721 - precision: 0.9273 - recall: 0.7520 - categorical_accuracy: 0.8103 - val_loss: 0.3465 - val_precision: 0.9658 - val_recall: 0.8202 - val_categorical_accuracy: 0.8696 - lr: 3.2000e-04\n",
      "Epoch 76/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4724 - precision: 0.9265 - recall: 0.7520 - categorical_accuracy: 0.8080 - val_loss: 0.3407 - val_precision: 0.9662 - val_recall: 0.8202 - val_categorical_accuracy: 0.8695 - lr: 2.5600e-04\n",
      "Epoch 77/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4617 - precision: 0.9307 - recall: 0.7542 - categorical_accuracy: 0.8115 - val_loss: 0.3406 - val_precision: 0.9669 - val_recall: 0.8220 - val_categorical_accuracy: 0.8702 - lr: 2.5600e-04\n",
      "Epoch 78/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.4610 - precision: 0.9317 - recall: 0.7545 - categorical_accuracy: 0.8126 - val_loss: 0.3407 - val_precision: 0.9675 - val_recall: 0.8200 - val_categorical_accuracy: 0.8698 - lr: 2.5600e-04\n",
      "Epoch 79/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.4670 - precision: 0.9293 - recall: 0.7512 - categorical_accuracy: 0.8076 - val_loss: 0.3397 - val_precision: 0.9669 - val_recall: 0.8222 - val_categorical_accuracy: 0.8709 - lr: 2.5600e-04\n",
      "Epoch 80/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.4571 - precision: 0.9311 - recall: 0.7604 - categorical_accuracy: 0.8198 - val_loss: 0.3387 - val_precision: 0.9673 - val_recall: 0.8229 - val_categorical_accuracy: 0.8703 - lr: 2.5600e-04\n",
      "Epoch 81/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4583 - precision: 0.9309 - recall: 0.7589 - categorical_accuracy: 0.8147 - val_loss: 0.3390 - val_precision: 0.9658 - val_recall: 0.8230 - val_categorical_accuracy: 0.8703 - lr: 2.5600e-04\n",
      "Epoch 82/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4641 - precision: 0.9334 - recall: 0.7568 - categorical_accuracy: 0.8150 - val_loss: 0.3385 - val_precision: 0.9644 - val_recall: 0.8248 - val_categorical_accuracy: 0.8697 - lr: 2.5600e-04\n",
      "Epoch 83/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.4534 - precision: 0.9351 - recall: 0.7634 - categorical_accuracy: 0.8220 - val_loss: 0.3403 - val_precision: 0.9655 - val_recall: 0.8217 - val_categorical_accuracy: 0.8693 - lr: 2.5600e-04\n",
      "Epoch 84/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4601 - precision: 0.9292 - recall: 0.7572 - categorical_accuracy: 0.8118 - val_loss: 0.3374 - val_precision: 0.9666 - val_recall: 0.8224 - val_categorical_accuracy: 0.8698 - lr: 2.5600e-04\n",
      "Epoch 85/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.4533 - precision: 0.9334 - recall: 0.7584 - categorical_accuracy: 0.8166 - val_loss: 0.3387 - val_precision: 0.9635 - val_recall: 0.8225 - val_categorical_accuracy: 0.8700 - lr: 2.5600e-04\n",
      "Epoch 86/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.4566 - precision: 0.9360 - recall: 0.7625 - categorical_accuracy: 0.8204 - val_loss: 0.3379 - val_precision: 0.9665 - val_recall: 0.8234 - val_categorical_accuracy: 0.8713 - lr: 2.5600e-04\n",
      "Epoch 87/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.4562 - precision: 0.9346 - recall: 0.7611 - categorical_accuracy: 0.8199 - val_loss: 0.3379 - val_precision: 0.9659 - val_recall: 0.8236 - val_categorical_accuracy: 0.8710 - lr: 2.5600e-04\n",
      "Epoch 88/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4564 - precision: 0.9309 - recall: 0.7615 - categorical_accuracy: 0.8161 - val_loss: 0.3328 - val_precision: 0.9661 - val_recall: 0.8251 - val_categorical_accuracy: 0.8719 - lr: 2.5600e-04\n",
      "Epoch 89/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4457 - precision: 0.9373 - recall: 0.7640 - categorical_accuracy: 0.8215 - val_loss: 0.3363 - val_precision: 0.9661 - val_recall: 0.8227 - val_categorical_accuracy: 0.8713 - lr: 2.5600e-04\n",
      "Epoch 90/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4486 - precision: 0.9326 - recall: 0.7623 - categorical_accuracy: 0.8171 - val_loss: 0.3351 - val_precision: 0.9669 - val_recall: 0.8240 - val_categorical_accuracy: 0.8709 - lr: 2.5600e-04\n",
      "Epoch 91/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.4511 - precision: 0.9353 - recall: 0.7595 - categorical_accuracy: 0.8200 - val_loss: 0.3372 - val_precision: 0.9656 - val_recall: 0.8240 - val_categorical_accuracy: 0.8703 - lr: 2.5600e-04\n",
      "Epoch 92/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4529 - precision: 0.9342 - recall: 0.7629 - categorical_accuracy: 0.8197 - val_loss: 0.3366 - val_precision: 0.9656 - val_recall: 0.8236 - val_categorical_accuracy: 0.8715 - lr: 2.5600e-04\n",
      "Epoch 93/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.4502 - precision: 0.9347 - recall: 0.7620 - categorical_accuracy: 0.8182 - val_loss: 0.3321 - val_precision: 0.9656 - val_recall: 0.8234 - val_categorical_accuracy: 0.8705 - lr: 2.5600e-04\n",
      "Epoch 94/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4425 - precision: 0.9374 - recall: 0.7657 - categorical_accuracy: 0.8239 - val_loss: 0.3298 - val_precision: 0.9667 - val_recall: 0.8256 - val_categorical_accuracy: 0.8714 - lr: 2.0480e-04\n",
      "Epoch 95/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4409 - precision: 0.9354 - recall: 0.7649 - categorical_accuracy: 0.8184 - val_loss: 0.3310 - val_precision: 0.9663 - val_recall: 0.8252 - val_categorical_accuracy: 0.8716 - lr: 2.0480e-04\n",
      "Epoch 96/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4385 - precision: 0.9336 - recall: 0.7662 - categorical_accuracy: 0.8197 - val_loss: 0.3299 - val_precision: 0.9667 - val_recall: 0.8264 - val_categorical_accuracy: 0.8727 - lr: 2.0480e-04\n",
      "Epoch 97/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.4352 - precision: 0.9389 - recall: 0.7678 - categorical_accuracy: 0.8270 - val_loss: 0.3271 - val_precision: 0.9677 - val_recall: 0.8263 - val_categorical_accuracy: 0.8725 - lr: 2.0480e-04\n",
      "Epoch 98/150\n",
      "348/348 [==============================] - 5s 11ms/step - loss: 0.4350 - precision: 0.9344 - recall: 0.7661 - categorical_accuracy: 0.8207 - val_loss: 0.3276 - val_precision: 0.9670 - val_recall: 0.8256 - val_categorical_accuracy: 0.8724 - lr: 2.0480e-04\n",
      "Epoch 99/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.4411 - precision: 0.9368 - recall: 0.7645 - categorical_accuracy: 0.8219 - val_loss: 0.3284 - val_precision: 0.9662 - val_recall: 0.8256 - val_categorical_accuracy: 0.8717 - lr: 2.0480e-04\n",
      "Epoch 100/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.4393 - precision: 0.9350 - recall: 0.7670 - categorical_accuracy: 0.8236 - val_loss: 0.3319 - val_precision: 0.9672 - val_recall: 0.8234 - val_categorical_accuracy: 0.8715 - lr: 2.0480e-04\n",
      "Epoch 101/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4350 - precision: 0.9365 - recall: 0.7658 - categorical_accuracy: 0.8260 - val_loss: 0.3281 - val_precision: 0.9661 - val_recall: 0.8262 - val_categorical_accuracy: 0.8726 - lr: 2.0480e-04\n",
      "Epoch 102/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4349 - precision: 0.9401 - recall: 0.7710 - categorical_accuracy: 0.8279 - val_loss: 0.3289 - val_precision: 0.9669 - val_recall: 0.8260 - val_categorical_accuracy: 0.8720 - lr: 2.0480e-04\n",
      "Epoch 103/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4310 - precision: 0.9384 - recall: 0.7674 - categorical_accuracy: 0.8227 - val_loss: 0.3253 - val_precision: 0.9668 - val_recall: 0.8265 - val_categorical_accuracy: 0.8722 - lr: 1.6384e-04\n",
      "Epoch 104/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4310 - precision: 0.9378 - recall: 0.7682 - categorical_accuracy: 0.8247 - val_loss: 0.3248 - val_precision: 0.9668 - val_recall: 0.8268 - val_categorical_accuracy: 0.8728 - lr: 1.6384e-04\n",
      "Epoch 105/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.4247 - precision: 0.9410 - recall: 0.7713 - categorical_accuracy: 0.8255 - val_loss: 0.3253 - val_precision: 0.9672 - val_recall: 0.8262 - val_categorical_accuracy: 0.8728 - lr: 1.6384e-04\n",
      "Epoch 106/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4269 - precision: 0.9378 - recall: 0.7705 - categorical_accuracy: 0.8242 - val_loss: 0.3266 - val_precision: 0.9679 - val_recall: 0.8256 - val_categorical_accuracy: 0.8725 - lr: 1.6384e-04\n",
      "Epoch 107/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.4221 - precision: 0.9393 - recall: 0.7746 - categorical_accuracy: 0.8259 - val_loss: 0.3229 - val_precision: 0.9659 - val_recall: 0.8266 - val_categorical_accuracy: 0.8723 - lr: 1.6384e-04\n",
      "Epoch 108/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4323 - precision: 0.9397 - recall: 0.7691 - categorical_accuracy: 0.8240 - val_loss: 0.3248 - val_precision: 0.9668 - val_recall: 0.8262 - val_categorical_accuracy: 0.8719 - lr: 1.6384e-04\n",
      "Epoch 109/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4188 - precision: 0.9399 - recall: 0.7748 - categorical_accuracy: 0.8303 - val_loss: 0.3236 - val_precision: 0.9657 - val_recall: 0.8273 - val_categorical_accuracy: 0.8722 - lr: 1.6384e-04\n",
      "Epoch 110/150\n",
      "348/348 [==============================] - 5s 13ms/step - loss: 0.4258 - precision: 0.9391 - recall: 0.7726 - categorical_accuracy: 0.8282 - val_loss: 0.3219 - val_precision: 0.9668 - val_recall: 0.8263 - val_categorical_accuracy: 0.8724 - lr: 1.6384e-04\n",
      "Epoch 111/150\n",
      "348/348 [==============================] - 5s 13ms/step - loss: 0.4243 - precision: 0.9395 - recall: 0.7698 - categorical_accuracy: 0.8252 - val_loss: 0.3227 - val_precision: 0.9670 - val_recall: 0.8269 - val_categorical_accuracy: 0.8723 - lr: 1.6384e-04\n",
      "Epoch 112/150\n",
      "348/348 [==============================] - 5s 13ms/step - loss: 0.4218 - precision: 0.9392 - recall: 0.7725 - categorical_accuracy: 0.8267 - val_loss: 0.3243 - val_precision: 0.9662 - val_recall: 0.8271 - val_categorical_accuracy: 0.8718 - lr: 1.6384e-04\n",
      "Epoch 113/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4232 - precision: 0.9432 - recall: 0.7746 - categorical_accuracy: 0.8295 - val_loss: 0.3209 - val_precision: 0.9655 - val_recall: 0.8275 - val_categorical_accuracy: 0.8721 - lr: 1.3107e-04\n",
      "Epoch 114/150\n",
      "348/348 [==============================] - 5s 13ms/step - loss: 0.4157 - precision: 0.9419 - recall: 0.7790 - categorical_accuracy: 0.8299 - val_loss: 0.3194 - val_precision: 0.9667 - val_recall: 0.8279 - val_categorical_accuracy: 0.8729 - lr: 1.3107e-04\n",
      "Epoch 115/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.4154 - precision: 0.9387 - recall: 0.7735 - categorical_accuracy: 0.8257 - val_loss: 0.3198 - val_precision: 0.9671 - val_recall: 0.8279 - val_categorical_accuracy: 0.8731 - lr: 1.3107e-04\n",
      "Epoch 116/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.4208 - precision: 0.9408 - recall: 0.7762 - categorical_accuracy: 0.8281 - val_loss: 0.3208 - val_precision: 0.9672 - val_recall: 0.8278 - val_categorical_accuracy: 0.8725 - lr: 1.3107e-04\n",
      "Epoch 117/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4143 - precision: 0.9442 - recall: 0.7764 - categorical_accuracy: 0.8316 - val_loss: 0.3189 - val_precision: 0.9665 - val_recall: 0.8276 - val_categorical_accuracy: 0.8727 - lr: 1.3107e-04\n",
      "Epoch 118/150\n",
      "348/348 [==============================] - 6s 16ms/step - loss: 0.4134 - precision: 0.9420 - recall: 0.7771 - categorical_accuracy: 0.8295 - val_loss: 0.3170 - val_precision: 0.9661 - val_recall: 0.8284 - val_categorical_accuracy: 0.8724 - lr: 1.3107e-04\n",
      "Epoch 119/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4121 - precision: 0.9398 - recall: 0.7770 - categorical_accuracy: 0.8307 - val_loss: 0.3195 - val_precision: 0.9662 - val_recall: 0.8281 - val_categorical_accuracy: 0.8728 - lr: 1.3107e-04\n",
      "Epoch 120/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4150 - precision: 0.9450 - recall: 0.7764 - categorical_accuracy: 0.8308 - val_loss: 0.3184 - val_precision: 0.9669 - val_recall: 0.8270 - val_categorical_accuracy: 0.8728 - lr: 1.3107e-04\n",
      "Epoch 121/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4139 - precision: 0.9401 - recall: 0.7766 - categorical_accuracy: 0.8283 - val_loss: 0.3174 - val_precision: 0.9668 - val_recall: 0.8284 - val_categorical_accuracy: 0.8730 - lr: 1.3107e-04\n",
      "Epoch 122/150\n",
      "348/348 [==============================] - 5s 14ms/step - loss: 0.4125 - precision: 0.9462 - recall: 0.7786 - categorical_accuracy: 0.8288 - val_loss: 0.3170 - val_precision: 0.9662 - val_recall: 0.8286 - val_categorical_accuracy: 0.8733 - lr: 1.3107e-04\n",
      "Epoch 123/150\n",
      "348/348 [==============================] - 5s 14ms/step - loss: 0.4124 - precision: 0.9427 - recall: 0.7759 - categorical_accuracy: 0.8324 - val_loss: 0.3155 - val_precision: 0.9674 - val_recall: 0.8286 - val_categorical_accuracy: 0.8736 - lr: 1.3107e-04\n",
      "Epoch 124/150\n",
      "348/348 [==============================] - 6s 15ms/step - loss: 0.4052 - precision: 0.9449 - recall: 0.7823 - categorical_accuracy: 0.8321 - val_loss: 0.3152 - val_precision: 0.9671 - val_recall: 0.8288 - val_categorical_accuracy: 0.8739 - lr: 1.3107e-04\n",
      "Epoch 125/150\n",
      "348/348 [==============================] - 6s 15ms/step - loss: 0.4091 - precision: 0.9454 - recall: 0.7790 - categorical_accuracy: 0.8322 - val_loss: 0.3167 - val_precision: 0.9668 - val_recall: 0.8280 - val_categorical_accuracy: 0.8735 - lr: 1.3107e-04\n",
      "Epoch 126/150\n",
      "348/348 [==============================] - 6s 15ms/step - loss: 0.4062 - precision: 0.9429 - recall: 0.7782 - categorical_accuracy: 0.8318 - val_loss: 0.3147 - val_precision: 0.9661 - val_recall: 0.8292 - val_categorical_accuracy: 0.8731 - lr: 1.3107e-04\n",
      "Epoch 127/150\n",
      "348/348 [==============================] - 6s 15ms/step - loss: 0.4110 - precision: 0.9431 - recall: 0.7802 - categorical_accuracy: 0.8322 - val_loss: 0.3158 - val_precision: 0.9663 - val_recall: 0.8288 - val_categorical_accuracy: 0.8735 - lr: 1.3107e-04\n",
      "Epoch 128/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4089 - precision: 0.9402 - recall: 0.7786 - categorical_accuracy: 0.8301 - val_loss: 0.3154 - val_precision: 0.9665 - val_recall: 0.8285 - val_categorical_accuracy: 0.8735 - lr: 1.3107e-04\n",
      "Epoch 129/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.4055 - precision: 0.9430 - recall: 0.7802 - categorical_accuracy: 0.8324 - val_loss: 0.3148 - val_precision: 0.9674 - val_recall: 0.8291 - val_categorical_accuracy: 0.8739 - lr: 1.0486e-04\n",
      "Epoch 130/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.4046 - precision: 0.9421 - recall: 0.7790 - categorical_accuracy: 0.8343 - val_loss: 0.3134 - val_precision: 0.9654 - val_recall: 0.8298 - val_categorical_accuracy: 0.8738 - lr: 1.0486e-04\n",
      "Epoch 131/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.4043 - precision: 0.9431 - recall: 0.7789 - categorical_accuracy: 0.8307 - val_loss: 0.3143 - val_precision: 0.9667 - val_recall: 0.8286 - val_categorical_accuracy: 0.8737 - lr: 1.0486e-04\n",
      "Epoch 132/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4041 - precision: 0.9453 - recall: 0.7822 - categorical_accuracy: 0.8339 - val_loss: 0.3119 - val_precision: 0.9671 - val_recall: 0.8300 - val_categorical_accuracy: 0.8742 - lr: 1.0486e-04\n",
      "Epoch 133/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.3999 - precision: 0.9456 - recall: 0.7824 - categorical_accuracy: 0.8355 - val_loss: 0.3123 - val_precision: 0.9669 - val_recall: 0.8298 - val_categorical_accuracy: 0.8743 - lr: 1.0486e-04\n",
      "Epoch 134/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.3974 - precision: 0.9455 - recall: 0.7810 - categorical_accuracy: 0.8348 - val_loss: 0.3112 - val_precision: 0.9648 - val_recall: 0.8314 - val_categorical_accuracy: 0.8740 - lr: 1.0486e-04\n",
      "Epoch 135/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4018 - precision: 0.9456 - recall: 0.7818 - categorical_accuracy: 0.8342 - val_loss: 0.3118 - val_precision: 0.9653 - val_recall: 0.8301 - val_categorical_accuracy: 0.8737 - lr: 1.0486e-04\n",
      "Epoch 136/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.4045 - precision: 0.9420 - recall: 0.7818 - categorical_accuracy: 0.8324 - val_loss: 0.3114 - val_precision: 0.9661 - val_recall: 0.8303 - val_categorical_accuracy: 0.8738 - lr: 1.0486e-04\n",
      "Epoch 137/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.3967 - precision: 0.9467 - recall: 0.7847 - categorical_accuracy: 0.8358 - val_loss: 0.3131 - val_precision: 0.9663 - val_recall: 0.8293 - val_categorical_accuracy: 0.8738 - lr: 1.0486e-04\n",
      "Epoch 138/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.3957 - precision: 0.9442 - recall: 0.7811 - categorical_accuracy: 0.8373 - val_loss: 0.3120 - val_precision: 0.9671 - val_recall: 0.8295 - val_categorical_accuracy: 0.8736 - lr: 8.3886e-05\n",
      "Epoch 139/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.4025 - precision: 0.9423 - recall: 0.7785 - categorical_accuracy: 0.8327 - val_loss: 0.3102 - val_precision: 0.9669 - val_recall: 0.8292 - val_categorical_accuracy: 0.8736 - lr: 8.3886e-05\n",
      "Epoch 140/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.3952 - precision: 0.9476 - recall: 0.7855 - categorical_accuracy: 0.8386 - val_loss: 0.3098 - val_precision: 0.9662 - val_recall: 0.8296 - val_categorical_accuracy: 0.8737 - lr: 8.3886e-05\n",
      "Epoch 141/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.3952 - precision: 0.9500 - recall: 0.7847 - categorical_accuracy: 0.8388 - val_loss: 0.3100 - val_precision: 0.9673 - val_recall: 0.8286 - val_categorical_accuracy: 0.8736 - lr: 8.3886e-05\n",
      "Epoch 142/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.3947 - precision: 0.9480 - recall: 0.7850 - categorical_accuracy: 0.8397 - val_loss: 0.3080 - val_precision: 0.9659 - val_recall: 0.8304 - val_categorical_accuracy: 0.8739 - lr: 8.3886e-05\n",
      "Epoch 143/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.3935 - precision: 0.9449 - recall: 0.7839 - categorical_accuracy: 0.8396 - val_loss: 0.3106 - val_precision: 0.9662 - val_recall: 0.8293 - val_categorical_accuracy: 0.8735 - lr: 8.3886e-05\n",
      "Epoch 144/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.3943 - precision: 0.9464 - recall: 0.7830 - categorical_accuracy: 0.8349 - val_loss: 0.3096 - val_precision: 0.9661 - val_recall: 0.8297 - val_categorical_accuracy: 0.8733 - lr: 8.3886e-05\n",
      "Epoch 145/150\n",
      "348/348 [==============================] - 4s 12ms/step - loss: 0.3987 - precision: 0.9459 - recall: 0.7812 - categorical_accuracy: 0.8358 - val_loss: 0.3078 - val_precision: 0.9676 - val_recall: 0.8299 - val_categorical_accuracy: 0.8745 - lr: 8.3886e-05\n",
      "Epoch 146/150\n",
      "348/348 [==============================] - 5s 12ms/step - loss: 0.3933 - precision: 0.9477 - recall: 0.7850 - categorical_accuracy: 0.8390 - val_loss: 0.3092 - val_precision: 0.9661 - val_recall: 0.8295 - val_categorical_accuracy: 0.8739 - lr: 8.3886e-05\n",
      "Epoch 147/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.3897 - precision: 0.9479 - recall: 0.7859 - categorical_accuracy: 0.8379 - val_loss: 0.3084 - val_precision: 0.9651 - val_recall: 0.8302 - val_categorical_accuracy: 0.8738 - lr: 8.3886e-05\n",
      "Epoch 148/150\n",
      "348/348 [==============================] - 5s 11ms/step - loss: 0.3896 - precision: 0.9429 - recall: 0.7836 - categorical_accuracy: 0.8365 - val_loss: 0.3076 - val_precision: 0.9655 - val_recall: 0.8308 - val_categorical_accuracy: 0.8744 - lr: 6.7109e-05\n",
      "Epoch 149/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.3930 - precision: 0.9437 - recall: 0.7838 - categorical_accuracy: 0.8361 - val_loss: 0.3082 - val_precision: 0.9658 - val_recall: 0.8301 - val_categorical_accuracy: 0.8740 - lr: 6.7109e-05\n",
      "Epoch 150/150\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 0.3921 - precision: 0.9487 - recall: 0.7847 - categorical_accuracy: 0.8379 - val_loss: 0.3069 - val_precision: 0.9663 - val_recall: 0.8305 - val_categorical_accuracy: 0.8741 - lr: 6.7109e-05\n"
     ]
    }
   ],
   "source": [
    "training_history = pretrained_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=150,\n",
    "    callbacks= callbacks,\n",
    "    validation_data=validation_dataset,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.84, Validation Accuracy: 0.87\n",
      "Training Precision: 0.95, Validation Precision: 0.97\n",
      "Training Recall: 0.78, Validation Recall: 0.83\n",
      "Training Loss: 0.39, Validation Loss: 0.31\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = training_history.history['categorical_accuracy'][-1]  # Last epoch's training accuracy\n",
    "val_accuracy = training_history.history['val_categorical_accuracy'][-1]  # Last epoch's validation accuracy\n",
    "\n",
    "# If Precision and Recall are included in the metrics\n",
    "train_precision = training_history.history['precision'][-1]\n",
    "val_precision = training_history.history['val_precision'][-1]\n",
    "\n",
    "train_recall = training_history.history['recall'][-1]\n",
    "val_recall = training_history.history['val_recall'][-1]\n",
    "\n",
    "train_loss = training_history.history['loss'][-1]\n",
    "val_loss = training_history.history['val_loss'][-1]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}, Validation Accuracy: {val_accuracy:.2f}\")\n",
    "print(f\"Training Precision: {train_precision:.2f}, Validation Precision: {val_precision:.2f}\")\n",
    "print(f\"Training Recall: {train_recall:.2f}, Validation Recall: {val_recall:.2f}\")\n",
    "print(f\"Training Loss: {train_loss:.2f}, Validation Loss: {val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 2s 5ms/step - loss: 0.3069 - precision: 0.9663 - recall: 0.8305 - categorical_accuracy: 0.8741\n",
      "{'loss': 0.3069431483745575, 'precision': 0.9662685990333557, 'recall': 0.8304672837257385, 'categorical_accuracy': 0.8741334080696106}\n"
     ]
    }
   ],
   "source": [
    "results = pretrained_model.evaluate(test_dataset)\n",
    "metric_names = pretrained_model.metrics_names  # Get metric names\n",
    "results_dict = dict(zip(metric_names, results))  # Create a dictionary\n",
    "\n",
    "print(results_dict)\n",
    "#print(f\"\\nFinal Test Accuracy: {test_accuracy:.4f},Final Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old\n",
    "Validation Accuracy: 0.9397\n",
    "Validation Loss: 0.1974\n",
    "Accuracy: 0.8877\n",
    "Loss: 0.2755\n",
    "\n",
    "Final Test Accuracy: 0.9246,Final Test Loss: 0.2040\n",
    "\n",
    "### after training pretrained model again\n",
    "Validation Accuracy: 0.87\n",
    "Validation Loss: 0.31\n",
    "Training Accuracy: 0.84\n",
    "Training Loss: 0.39\n",
    "\n",
    "{'loss': 0.3069431483745575, 'precision': 0.9662685990333557, 'recall': 0.8304672837257385, 'categorical_accuracy': 0.8741334080696106}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.save(os.path.join('models','re_trained_0.912.keras'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
